{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST-Keras.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIulV4K085DA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEFQBEmF-6UJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJdAjkaM_GDr",
        "colab_type": "code",
        "outputId": "c5e99452-3754-4658-d339-d83775b09b09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "\n",
        "#Check Target Variable\n",
        "\n",
        "train['label'].value_counts()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    4684\n",
              "7    4401\n",
              "3    4351\n",
              "9    4188\n",
              "2    4177\n",
              "6    4137\n",
              "0    4132\n",
              "4    4072\n",
              "8    4063\n",
              "5    3795\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZng4gO7RUMr",
        "colab_type": "code",
        "outputId": "a17fe90b-df16-4cc6-b818-1690b351160c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "#Seperating the target variable\n",
        "y_train = train['label'].values\n",
        "y_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, ..., 7, 6, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLz_fDZ1RVw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#deleting label\n",
        "del train['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_x9jX-ARXer",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train.iloc[:,:].values\n",
        "X_test  = test.iloc[:,:].values\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train/255\n",
        "X_test = X_test/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jF9DOrgRZpu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reshaping\n",
        "X_train = X_train.reshape(-1,28,28,1)\n",
        "X_test = X_test.reshape(-1,28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfQTpUJ7Rc1m",
        "colab_type": "code",
        "outputId": "65bc57cd-d8f6-4c9f-db2e-b50f7226c0d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "x = train\n",
        "x = x.values.reshape(-1,28,28,1)\n",
        "plt.imshow(x[8][:,:,0])\n",
        "del x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBIC8WWfRepe",
        "colab_type": "code",
        "outputId": "3509e5f8-0712-4f16-9e2b-6eb38c54701b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "from keras.utils import  to_categorical\n",
        "\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYyL4LsqRhN9",
        "colab_type": "code",
        "outputId": "538975c4-ecfd-47af-8b1f-f84d793fbf42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "y_train = to_categorical(y_train,10)\n",
        "y_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwWjY2ywRjUT",
        "colab_type": "code",
        "outputId": "48c888f3-e3d8-4c38-f7a6-88247c832cf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 981
        }
      },
      "source": [
        "import keras\n",
        "\n",
        "#Creating Model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32,(3,3),padding = 'same',input_shape = (28,28,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32,(3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.50))\n",
        "model.add(Dense(256))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 26, 26, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 11, 11, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 11, 11, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 512)               819712    \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "activation_23 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,050,218\n",
            "Trainable params: 1,050,218\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od3anl5BRq1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = Adam(lr = 0.001)\n",
        "#Training the model using Adam\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvzOvUIBRuFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "lr_reduction = ReduceLROnPlateau(monitor = 'acc',patience = 3,verbose = 1,factor = 0.2,min_lr = 0.00001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSYA1zz6RwHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(featurewise_center = False,\n",
        "                            samplewise_center = False,\n",
        "                            featurewise_std_normalization = False,\n",
        "                            samplewise_std_normalization = False,\n",
        "                            zca_whitening = False,\n",
        "                            rotation_range = 10,\n",
        "                            zoom_range = 0.1,\n",
        "                            width_shift_range = 0.1,\n",
        "                            height_shift_range = 0.1,\n",
        "                            horizontal_flip = False,\n",
        "                            vertical_flip = False)\n",
        "\n",
        "datagen.fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz8x9ztkRx_H",
        "colab_type": "code",
        "outputId": "7bfa71c8-c242-4a6c-e1ff-9d9c6af9efc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3763
        }
      },
      "source": [
        "history = model.fit_generator(datagen.flow(X_train,y_train,batch_size = 128),steps_per_epoch=60000//128, epochs = 100,verbose = 2,callbacks = [lr_reduction])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " - 23s - loss: 0.0634 - acc: 0.9813\n",
            "Epoch 2/100\n",
            " - 23s - loss: 0.0607 - acc: 0.9825\n",
            "Epoch 3/100\n",
            " - 23s - loss: 0.0531 - acc: 0.9847\n",
            "Epoch 4/100\n",
            " - 23s - loss: 0.0515 - acc: 0.9851\n",
            "Epoch 5/100\n",
            " - 24s - loss: 0.0484 - acc: 0.9860\n",
            "Epoch 6/100\n",
            " - 23s - loss: 0.0493 - acc: 0.9858\n",
            "Epoch 7/100\n",
            " - 23s - loss: 0.0489 - acc: 0.9862\n",
            "Epoch 8/100\n",
            " - 23s - loss: 0.0433 - acc: 0.9873\n",
            "Epoch 9/100\n",
            " - 23s - loss: 0.0433 - acc: 0.9873\n",
            "Epoch 10/100\n",
            " - 23s - loss: 0.0398 - acc: 0.9886\n",
            "Epoch 11/100\n",
            " - 23s - loss: 0.0382 - acc: 0.9891\n",
            "Epoch 12/100\n",
            " - 23s - loss: 0.0369 - acc: 0.9891\n",
            "Epoch 13/100\n",
            " - 23s - loss: 0.0365 - acc: 0.9892\n",
            "Epoch 14/100\n",
            " - 23s - loss: 0.0374 - acc: 0.9891\n",
            "Epoch 15/100\n",
            " - 23s - loss: 0.0328 - acc: 0.9906\n",
            "Epoch 16/100\n",
            " - 23s - loss: 0.0365 - acc: 0.9891\n",
            "Epoch 17/100\n",
            " - 23s - loss: 0.0352 - acc: 0.9900\n",
            "Epoch 18/100\n",
            " - 23s - loss: 0.0320 - acc: 0.9909\n",
            "Epoch 19/100\n",
            " - 23s - loss: 0.0325 - acc: 0.9906\n",
            "Epoch 20/100\n",
            " - 23s - loss: 0.0332 - acc: 0.9905\n",
            "Epoch 21/100\n",
            " - 23s - loss: 0.0324 - acc: 0.9906\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "Epoch 22/100\n",
            " - 23s - loss: 0.0222 - acc: 0.9935\n",
            "Epoch 23/100\n",
            " - 23s - loss: 0.0211 - acc: 0.9937\n",
            "Epoch 24/100\n",
            " - 23s - loss: 0.0187 - acc: 0.9944\n",
            "Epoch 25/100\n",
            " - 23s - loss: 0.0188 - acc: 0.9941\n",
            "Epoch 26/100\n",
            " - 23s - loss: 0.0166 - acc: 0.9952\n",
            "Epoch 27/100\n",
            " - 23s - loss: 0.0177 - acc: 0.9950\n",
            "Epoch 28/100\n",
            " - 23s - loss: 0.0177 - acc: 0.9949\n",
            "Epoch 29/100\n",
            " - 23s - loss: 0.0162 - acc: 0.9954\n",
            "Epoch 30/100\n",
            " - 23s - loss: 0.0165 - acc: 0.9948\n",
            "Epoch 31/100\n",
            " - 23s - loss: 0.0157 - acc: 0.9955\n",
            "Epoch 32/100\n",
            " - 23s - loss: 0.0150 - acc: 0.9952\n",
            "\n",
            "Epoch 00032: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "Epoch 33/100\n",
            " - 23s - loss: 0.0152 - acc: 0.9957\n",
            "Epoch 34/100\n",
            " - 23s - loss: 0.0140 - acc: 0.9956\n",
            "Epoch 35/100\n",
            " - 23s - loss: 0.0146 - acc: 0.9958\n",
            "Epoch 36/100\n",
            " - 23s - loss: 0.0148 - acc: 0.9956\n",
            "Epoch 37/100\n",
            " - 23s - loss: 0.0147 - acc: 0.9956\n",
            "Epoch 38/100\n",
            " - 23s - loss: 0.0127 - acc: 0.9961\n",
            "Epoch 39/100\n",
            " - 23s - loss: 0.0139 - acc: 0.9957\n",
            "Epoch 40/100\n",
            " - 23s - loss: 0.0140 - acc: 0.9958\n",
            "Epoch 41/100\n",
            " - 23s - loss: 0.0139 - acc: 0.9956\n",
            "\n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "Epoch 42/100\n",
            " - 23s - loss: 0.0128 - acc: 0.9961\n",
            "Epoch 43/100\n",
            " - 23s - loss: 0.0129 - acc: 0.9962\n",
            "Epoch 44/100\n",
            " - 23s - loss: 0.0135 - acc: 0.9958\n",
            "Epoch 45/100\n",
            " - 23s - loss: 0.0133 - acc: 0.9961\n",
            "Epoch 46/100\n",
            " - 23s - loss: 0.0142 - acc: 0.9956\n",
            "Epoch 47/100\n",
            " - 23s - loss: 0.0133 - acc: 0.9962\n",
            "Epoch 48/100\n",
            " - 23s - loss: 0.0128 - acc: 0.9960\n",
            "Epoch 49/100\n",
            " - 23s - loss: 0.0129 - acc: 0.9961\n",
            "Epoch 50/100\n",
            " - 23s - loss: 0.0132 - acc: 0.9961\n",
            "Epoch 51/100\n",
            " - 23s - loss: 0.0137 - acc: 0.9957\n",
            "Epoch 52/100\n",
            " - 23s - loss: 0.0119 - acc: 0.9966\n",
            "Epoch 53/100\n",
            " - 23s - loss: 0.0117 - acc: 0.9965\n",
            "Epoch 54/100\n",
            " - 23s - loss: 0.0122 - acc: 0.9964\n",
            "Epoch 55/100\n",
            " - 23s - loss: 0.0122 - acc: 0.9966\n",
            "Epoch 56/100\n",
            " - 23s - loss: 0.0125 - acc: 0.9962\n",
            "Epoch 57/100\n",
            " - 23s - loss: 0.0131 - acc: 0.9959\n",
            "Epoch 58/100\n",
            " - 23s - loss: 0.0119 - acc: 0.9961\n",
            "Epoch 59/100\n",
            " - 23s - loss: 0.0125 - acc: 0.9962\n",
            "Epoch 60/100\n",
            " - 23s - loss: 0.0125 - acc: 0.9961\n",
            "Epoch 61/100\n",
            " - 23s - loss: 0.0135 - acc: 0.9958\n",
            "Epoch 62/100\n",
            " - 23s - loss: 0.0128 - acc: 0.9959\n",
            "Epoch 63/100\n",
            " - 23s - loss: 0.0124 - acc: 0.9963\n",
            "Epoch 64/100\n",
            " - 23s - loss: 0.0118 - acc: 0.9963\n",
            "Epoch 65/100\n",
            " - 23s - loss: 0.0131 - acc: 0.9963\n",
            "Epoch 66/100\n",
            " - 23s - loss: 0.0121 - acc: 0.9960\n",
            "Epoch 67/100\n",
            " - 23s - loss: 0.0119 - acc: 0.9965\n",
            "Epoch 68/100\n",
            " - 23s - loss: 0.0126 - acc: 0.9963\n",
            "Epoch 69/100\n",
            " - 23s - loss: 0.0124 - acc: 0.9963\n",
            "Epoch 70/100\n",
            " - 23s - loss: 0.0124 - acc: 0.9963\n",
            "Epoch 71/100\n",
            " - 23s - loss: 0.0125 - acc: 0.9961\n",
            "Epoch 72/100\n",
            " - 23s - loss: 0.0129 - acc: 0.9965\n",
            "Epoch 73/100\n",
            " - 23s - loss: 0.0130 - acc: 0.9959\n",
            "Epoch 74/100\n",
            " - 23s - loss: 0.0116 - acc: 0.9962\n",
            "Epoch 75/100\n",
            " - 23s - loss: 0.0127 - acc: 0.9960\n",
            "Epoch 76/100\n",
            " - 23s - loss: 0.0133 - acc: 0.9965\n",
            "Epoch 77/100\n",
            " - 23s - loss: 0.0126 - acc: 0.9963\n",
            "Epoch 78/100\n",
            " - 23s - loss: 0.0125 - acc: 0.9962\n",
            "Epoch 79/100\n",
            " - 23s - loss: 0.0132 - acc: 0.9961\n",
            "Epoch 80/100\n",
            " - 23s - loss: 0.0125 - acc: 0.9962\n",
            "Epoch 81/100\n",
            " - 23s - loss: 0.0122 - acc: 0.9963\n",
            "Epoch 82/100\n",
            " - 23s - loss: 0.0119 - acc: 0.9964\n",
            "Epoch 83/100\n",
            " - 23s - loss: 0.0124 - acc: 0.9963\n",
            "Epoch 84/100\n",
            " - 23s - loss: 0.0128 - acc: 0.9963\n",
            "Epoch 85/100\n",
            " - 23s - loss: 0.0124 - acc: 0.9963\n",
            "Epoch 86/100\n",
            " - 23s - loss: 0.0136 - acc: 0.9961\n",
            "Epoch 87/100\n",
            " - 23s - loss: 0.0109 - acc: 0.9967\n",
            "Epoch 88/100\n",
            " - 23s - loss: 0.0108 - acc: 0.9966\n",
            "Epoch 89/100\n",
            " - 23s - loss: 0.0116 - acc: 0.9964\n",
            "Epoch 90/100\n",
            " - 23s - loss: 0.0112 - acc: 0.9965\n",
            "Epoch 91/100\n",
            " - 23s - loss: 0.0123 - acc: 0.9962\n",
            "Epoch 92/100\n",
            " - 23s - loss: 0.0115 - acc: 0.9966\n",
            "Epoch 93/100\n",
            " - 23s - loss: 0.0123 - acc: 0.9963\n",
            "Epoch 94/100\n",
            " - 23s - loss: 0.0115 - acc: 0.9965\n",
            "Epoch 95/100\n",
            " - 23s - loss: 0.0110 - acc: 0.9966\n",
            "Epoch 96/100\n",
            " - 23s - loss: 0.0113 - acc: 0.9965\n",
            "Epoch 97/100\n",
            " - 23s - loss: 0.0117 - acc: 0.9966\n",
            "Epoch 98/100\n",
            " - 23s - loss: 0.0110 - acc: 0.9967\n",
            "Epoch 99/100\n",
            " - 23s - loss: 0.0108 - acc: 0.9967\n",
            "Epoch 100/100\n",
            " - 23s - loss: 0.0117 - acc: 0.9966\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}